{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c97549b-0e99-4511-8989-51ba49a6e3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection_data = \"Spark The Definitive Guide: Big Data Processing Made Simple\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ac7a6b3-869b-4d6c-9bdd-46b5c93baa94",
   "metadata": {},
   "outputs": [],
   "source": [
    "supplementData = {\n",
    "    \"Spark\":1000, \"Definitive\":200, \"Big\":300, \"Simple\":100\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8054e08f-819e-414d-8e0a-f113ea7a3981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48f3732a-32fd-4613-8247-d28252c7c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "suppBroadcast = spark.sparkContext.broadcast(supplementData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a147e30e-1382-46d7-995c-f803f3de6a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Spark': 1000, 'Definitive': 200, 'Big': 300, 'Simple': 100}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "suppBroadcast.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc081e33-8fce-40ba-a8ba-0e7df94919de",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = spark.sparkContext.parallelize(collection_data.split(), 2) #RDD형태로 변경, 파티션 수는 2개"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6bb525b7-1ae9-4694-8708-02836d192027",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('Spark', 1000),\n",
       " ('Big', 300),\n",
       " ('Definitive', 200),\n",
       " ('Simple', 100),\n",
       " ('The', 0),\n",
       " ('Guide:', 0),\n",
       " ('Data', 0),\n",
       " ('Processing', 0),\n",
       " ('Made', 0)]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "words.map(lambda word : (word, suppBroadcast.value.get(word, 0))).sortBy(lambda x:x[1], ascending=False).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1b2e043c-267e-498d-ac74-9479796e437d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "flight = spark.read.parquet('/root/spark-3.5.1/flight_data/parquet/24.03.20_spark.gz.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ebd54db-d6ff-414c-9453-685e888806b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|            Romania|    1|\n",
      "|    United States|            Ireland|  264|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "flight.show(2) #분할된 표를 볼때는 show\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ddccc5c6-5950-40a4-90d4-cc38f8aab8f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 항공표 추적하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "12db5ca0-5ec5-446b-930f-76e19a2ac2e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|        South Korea|  621|\n",
      "|      South Korea|      United States|  683|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 한국 관련된 항공편\n",
    "# sql 사용\n",
    "flight.createOrReplaceTempView('flight') #임시뷰 생성\n",
    "spark.sql(\"select * from flight where ORIGIN_COUNTRY_NAME like '%Korea%' or DEST_COUNTRY_NAME like '%Korea%'\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "357c7f66-b669-414a-9161-2a0092a5b352",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    United States|        South Korea|  621|\n",
      "|      South Korea|      United States|  683|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 함수 사용\n",
    "from pyspark.sql.functions import col, lower\n",
    "flight.filter(lower(col('ORIGIN_COUNTRY_NAME')).like('%kor%') | lower(col('DEST_COUNTRY_NAME')).like('%kor%')).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e9c96181-49e0-4213-ae00-754dceb28f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accumulator 분산 환경에서 공유되는 변수 - 여러 작업에서 공통적으로 사용되는 값을 수집\n",
    "#읽기 전용\n",
    "#클러스터의 각 노드에 값을 추가, 로컬ㅇ[서느느 변경할 수 없움\n",
    "# 디버깅을 정보수집이나 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea577b67-abd5-4bbe-b99e-c2d5502c9d58",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "05d13356-8042-4c42-84d3-86b584fc9ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 세션 새로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4bb8826e-6c9b-4ff8-9f3f-f70740bc88bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7292df6a-37be-4b19-85fd-fec1c152bd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_spartk = SparkSession.builder.appName(\"new spark session\").master(\"local[*]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1cd0be1a-3d89-48bd-a22d-e87182ba5a45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.session.SparkSession.Builder at 0x7f56a5ab36a0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_spartk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f27991ac-7bb4-4d57-ae75-0f8441a421b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 33:>                                                         (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------+\n",
      "|is_glass| count|\n",
      "+--------+------+\n",
      "|    NULL|  1454|\n",
      "|    true| 12861|\n",
      "|   false|527594|\n",
      "+--------+------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "spark.read.options(header = 'true', inferSchema = 'true').csv('/root/spark-3.5.1/online-dataset.csv').repartition(2)\\\n",
    ".selectExpr(\"instr(Description, 'GLASS') >= 1 as is_glass\")\\\n",
    ".groupBy(\"is_glass\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "44014c60-0a6a-4101-bf15-20a64ab6f8bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cashing --- 성능 튜닝"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4e5dd398-9141-4ed7-8037-c07e41ffbcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b397b55c-f44d-4c02-a901-474d2cf04f27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "origin_file_path = '/root/spark-3.5.1/bydata/by-day/*.csv'\n",
    "df_1 = spark.read.options(header = 'true', inferSchema = 'true').csv(origin_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d6feb34a-54fb-4326-8eb8-1f319f8f09e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+-------------------+--------+-------------------+---------+----------+--------------+\n",
      "|InvoiceNo|StockCode|        Description|Quantity|        InvoiceDate|UnitPrice|CustomerID|       Country|\n",
      "+---------+---------+-------------------+--------+-------------------+---------+----------+--------------+\n",
      "|   580538|    23084| RABBIT NIGHT LIGHT|      48|2011-12-05 08:38:00|     1.79|   14075.0|United Kingdom|\n",
      "|   580538|    23077|DOUGHNUT LIP GLOSS |      20|2011-12-05 08:38:00|     1.25|   14075.0|United Kingdom|\n",
      "+---------+---------+-------------------+--------+-------------------+---------+----------+--------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_1.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "52670d7f-bd2b-4f2f-975b-d83d4bce8c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 Country로 묶어서 count해서 df2에 저장\n",
    "df_1.createOrReplaceTempView('df1')\n",
    "df2 = spark.sql(\"select Country, count(Country) from df1 group by Country\")\n",
    "df3 = spark.sql(\"select CustomerID, count(CustomerID) from df1 group by CustomerID\")\n",
    "df4 = spark.sql(\"select InvoiceNo, count(InvoiceNo) from df1 group by InvoiceNo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "4142221b-d868-41e4-a569-3b3b638061cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시간 :  2024-03-26 12:39:56\n",
      "+---------+-----+\n",
      "|  Country|count|\n",
      "+---------+-----+\n",
      "|   Sweden|  462|\n",
      "|Singapore|  229|\n",
      "|  Germany| 9495|\n",
      "|      RSA|   58|\n",
      "|   France| 8557|\n",
      "+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "시간 :  2024-03-26 12:39:57\n",
      "+----------+-----+\n",
      "|CustomerID|count|\n",
      "+----------+-----+\n",
      "|   14452.0|   62|\n",
      "|   16916.0|  143|\n",
      "|   17633.0|   72|\n",
      "|   14768.0|    6|\n",
      "|   13094.0|   30|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "시간 :  2024-03-26 12:39:57\n",
      "+---------+-----+\n",
      "|InvoiceNo|count|\n",
      "+---------+-----+\n",
      "|   574966|    8|\n",
      "|   575091|   38|\n",
      "|   578057|   28|\n",
      "|   537252|    1|\n",
      "|   578459|    8|\n",
      "+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "시간 :  2024-03-26 12:39:57\n"
     ]
    }
   ],
   "source": [
    "# 함수 사용\n",
    "# 캐싱전\n",
    "def getCountGroupby(dataframe, colname):\n",
    "    return dataframe.groupBy(colname).count().show(5)\n",
    "\n",
    "print(\"시간 : \", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "getCountGroupby(df_1, 'Country')\n",
    "print(\"시간 : \", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "getCountGroupby(df_1, 'CustomerID')\n",
    "print(\"시간 : \", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "getCountGroupby(df_1, 'InvoiceNo')\n",
    "print(\"시간 : \", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d3c859f6-3eb4-4d98-8515-9d612670a9b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "시간 :  2024-03-26 12:37:19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/26 12:37:19 WARN CacheManager: Asked to cache already cached data.\n",
      "24/03/26 12:37:21 WARN CacheManager: Asked to cache already cached data.        \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+-----+\n",
      "|  Country|count|\n",
      "+---------+-----+\n",
      "|   Sweden|  462|\n",
      "|Singapore|  229|\n",
      "|  Germany| 9495|\n",
      "|      RSA|   58|\n",
      "|   France| 8557|\n",
      "+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "시간 :  2024-03-26 12:37:21\n",
      "+----------+-----+\n",
      "|CustomerID|count|\n",
      "+----------+-----+\n",
      "|   14452.0|   62|\n",
      "|   16916.0|  143|\n",
      "|   17633.0|   72|\n",
      "|   14768.0|    6|\n",
      "|   13094.0|   30|\n",
      "+----------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "시간 :  2024-03-26 12:37:21\n",
      "+---------+-----+\n",
      "|InvoiceNo|count|\n",
      "+---------+-----+\n",
      "|   574966|    8|\n",
      "|   575091|   38|\n",
      "|   578057|   28|\n",
      "|   537252|    1|\n",
      "|   578459|    8|\n",
      "+---------+-----+\n",
      "only showing top 5 rows\n",
      "\n",
      "시간 :  2024-03-26 12:37:21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/26 12:37:21 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    }
   ],
   "source": [
    "def getCountGroupby(dataframe, colname):\n",
    "    result = dataframe.groupBy(colname).count().cache()  # 캐싱\n",
    "    result.show(5)  # 결과 출력\n",
    "    return result  # 캐싱된 결과 반환\n",
    "    \n",
    "print(\"시간 : \", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "getCountGroupby(df1, 'Country')\n",
    "print(\"시간 : \", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "getCountGroupby(df1, 'CustomerID')\n",
    "print(\"시간 : \", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))\n",
    "\n",
    "getCountGroupby(df1, 'InvoiceNo')\n",
    "print(\"시간 : \", datetime.now().strftime('%Y-%m-%d %H:%M:%S'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "c2fa2dc1-7bc2-4743-803b-49a91795c6ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+\n",
      "|    Country|count(Country)|\n",
      "+-----------+--------------+\n",
      "|     Sweden|           462|\n",
      "|    Germany|          9495|\n",
      "|     France|          8557|\n",
      "|     Greece|           146|\n",
      "|    Belgium|          2069|\n",
      "|    Finland|           695|\n",
      "|      Malta|           127|\n",
      "|Unspecified|           446|\n",
      "|      Italy|           803|\n",
      "|       EIRE|          8196|\n",
      "+-----------+--------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------+-----------------+\n",
      "|CustomerID|count(CustomerID)|\n",
      "+----------+-----------------+\n",
      "|   14452.0|               62|\n",
      "|   16916.0|              143|\n",
      "|   17633.0|               72|\n",
      "|   14768.0|                6|\n",
      "|   13094.0|               30|\n",
      "|   17884.0|              117|\n",
      "|   16596.0|               12|\n",
      "|   15145.0|               67|\n",
      "|   16858.0|               13|\n",
      "|   13160.0|                4|\n",
      "+----------+-----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 103:==================================================>     (9 + 1) / 10]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+----------------+\n",
      "|InvoiceNo|count(InvoiceNo)|\n",
      "+---------+----------------+\n",
      "|   574966|               8|\n",
      "|   575091|              38|\n",
      "|   578057|              28|\n",
      "|   537252|               1|\n",
      "|   578459|               8|\n",
      "|  C578132|               1|\n",
      "|   578292|              72|\n",
      "|   576112|              20|\n",
      "|   577022|              38|\n",
      "|   574592|               8|\n",
      "+---------+----------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df2.show(10)\n",
    "df3.show(10)\n",
    "df4.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0d2bc0-5ca2-447e-97c8-2d2068af570d",
   "metadata": {},
   "source": [
    "## activity-data 이용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c7432eb7-484e-49e5-bdb0-33b429f3e127",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  /root/spark-3.5.1/a-data.zip\n",
      "  inflating: activity-data/_committed_730451297822678341  \n",
      " extracting: activity-data/_started_730451297822678341  \n",
      " extracting: activity-data/_SUCCESS  \n",
      "  inflating: activity-data/part-00000-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00001-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00002-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00003-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00004-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00005-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00006-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00007-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00008-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00009-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00010-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00011-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00012-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00013-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00014-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00015-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00016-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00017-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00018-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00019-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00020-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00021-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00022-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00023-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00024-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00025-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00026-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00027-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00028-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00029-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00030-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00031-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00032-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00033-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00034-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00035-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00036-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00037-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00038-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00039-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00040-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00041-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00042-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00043-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00044-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00045-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00046-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00047-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00048-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00049-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00050-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00051-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00052-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00053-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00054-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00055-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00056-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00057-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00058-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00059-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00060-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00061-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00062-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00063-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00064-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00065-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00066-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00067-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00068-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00069-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00070-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00071-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00072-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00073-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00074-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00075-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00076-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00077-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00078-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n",
      "  inflating: activity-data/part-00079-tid-730451297822678341-1dda7027-2071-4d73-a0e2-7fb6a91e1d1f-0-c000.json  \n"
     ]
    }
   ],
   "source": [
    "!unzip '/root/spark-3.5.1/a-data.zip'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "269000c5-9428-42e1-8f8c-da0d47862392",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.shuffle.partitions',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c46b0e3-5b4e-4f3f-a1ee-23dadbb2e53c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "static = spark.read.json('/root/spark-3.5.1/activity-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ad356c81-a0d6-4edd-8f41-222861a65e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming = spark.readStream.schema(static.schema).option('maxFilePerTrigger', 10).json('/root/spark-3.5.1/activity-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "44ca1635-3a6f-49c9-80a2-58dba45c7891",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------------------+--------+-----+------+----+-----+------------+------------+------------+\n",
      "| Arrival_Time|      Creation_Time|  Device|Index| Model|User|   gt|           x|           y|           z|\n",
      "+-------------+-------------------+--------+-----+------+----+-----+------------+------------+------------+\n",
      "|1424686735090|1424686733090638193|nexus4_1|   18|nexus4|   g|stand| 3.356934E-4|-5.645752E-4|-0.018814087|\n",
      "|1424686735292|1424688581345918092|nexus4_2|   66|nexus4|   g|stand|-0.005722046| 0.029083252| 0.005569458|\n",
      "+-------------+-------------------+--------+-----+------+----+-----+------------+------------+------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "static.show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dcb92743-bc7f-45d0-9271-17e04f6424e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "eventTime = streaming.selectExpr(\"*\", \"cast(cast(Creation_Time as double)/1000000000 as timestamp) as event_time\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9ae1ee46-2722-4893-904a-5f344af4df11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4041'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc.uiWebUrl.split(':')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "043ed98c-e483-4adf-99b5-32b17ff1ea20",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/26 13:23:33 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-e22c8fda-cd9f-450c-ae9e-57ac5a950a61. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "24/03/26 13:23:34 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7f010edc71f0>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 6:===========================================>              (9 + 1) / 12]\r"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, window\n",
    "eventTime.groupBy(window(col(\"event_time\"),\"10 minutes\")).count().writeStream.queryName(\"pyevent_per_window\").format(\"memory\")\\\n",
    ".outputMode(\"complete\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "09df25c8-8607-4b55-a5f4-050ad6f4804c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/26 13:24:16 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-9b456a95-b82b-4f43-8d24-707bb409bce8. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "24/03/26 13:24:16 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7f010dd67220>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "eventTime.groupBy(window(col(\"event_time\"),\"10 minutes\", \"5 minutes\")).count().writeStream.queryName(\"pyevent_per_window2\").format(\"memory\")\\\n",
    ".outputMode(\"complete\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fd6b3fc7-0019-401e-ab4e-cadc04350f28",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/03/26 13:28:31 WARN ResolveWriteToStream: Temporary checkpoint location created which is deleted normally when the query didn't fail: /tmp/temporary-78657cde-b988-48eb-8f5e-fee46994fd8b. If it's required to delete it under any circumstances, please set spark.sql.streaming.forceDeleteTempCheckpointLocation to true. Important to know deleting temp checkpoint folder is best effort.\n",
      "24/03/26 13:28:31 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7f010edd6700>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 12:===================>                                     (4 + 1) / 12]\r"
     ]
    }
   ],
   "source": [
    "eventTime.withWatermark(\"event_time\", \"30 minutes\")\\\n",
    ".groupBy(window(col(\"event_time\"),\"10 minutes\", \"5 minutes\"))\\\n",
    ".count().writeStream.queryName(\"pyevent_per_window3\").format(\"memory\").outputMode(\"complete\").start()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4cc45877-d660-4c81-b692-1ed488cdcd58",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[30], line 6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# eventTime.withWatermark(\"event_time\", \"5 seconds\")\\\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# .dropDuplicates([\"User\", \"event_time\"])\\\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# .groupBy(\"User\")\\\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# .count().writeStream.queryName(\"pyevent_per_window4\").format(\"memory\").outputMode(\"complete\").start()\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[43meventTime\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithWatermark\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mevent_time\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m5 seconds\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\\\n\u001b[1;32m      7\u001b[0m \u001b[38;5;241m.\u001b[39mdropDuplicates([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevent_time\u001b[39m\u001b[38;5;124m\"\u001b[39m])\\\n\u001b[1;32m      8\u001b[0m \u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUser\u001b[39m\u001b[38;5;124m\"\u001b[39m)\\\n\u001b[1;32m      9\u001b[0m \u001b[38;5;241m.\u001b[39mcount()\u001b[38;5;241m.\u001b[39mwriteStream\u001b[38;5;241m.\u001b[39mqueryName(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyevent_per_window4\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mformat(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39moutputMode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomplete\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mstop()\n",
      "File \u001b[0;32m~/spark-3.5.1/python/pyspark/sql/dataframe.py:1147\u001b[0m, in \u001b[0;36mDataFrame.withWatermark\u001b[0;34m(self, eventTime, delayThreshold)\u001b[0m\n\u001b[1;32m   1139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m delayThreshold \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(delayThreshold) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   1140\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PySparkTypeError(\n\u001b[1;32m   1141\u001b[0m         error_class\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNOT_STR\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1142\u001b[0m         message_parameters\u001b[38;5;241m=\u001b[39m{\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1145\u001b[0m         },\n\u001b[1;32m   1146\u001b[0m     )\n\u001b[0;32m-> 1147\u001b[0m jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithWatermark\u001b[49m\u001b[43m(\u001b[49m\u001b[43meventTime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelayThreshold\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1148\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparkSession)\n",
      "File \u001b[0;32m~/spark-3.5.1/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1314\u001b[0m args_command, temp_args \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_args(\u001b[38;5;241m*\u001b[39margs)\n\u001b[1;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[1;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[1;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n",
      "File \u001b[0;32m~/spark-3.5.1/python/lib/py4j-0.10.9.7-src.zip/py4j/java_gateway.py:1036\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msend_command\u001b[39m(\u001b[38;5;28mself\u001b[39m, command, retry\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, binary\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   1016\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Sends a command to the JVM. This method is not intended to be\u001b[39;00m\n\u001b[1;32m   1017\u001b[0m \u001b[38;5;124;03m       called directly by Py4J users. It is usually called by\u001b[39;00m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;124;03m       :class:`JavaMember` instances.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1034\u001b[0m \u001b[38;5;124;03m     if `binary` is `True`.\u001b[39;00m\n\u001b[1;32m   1035\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1036\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1037\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1038\u001b[0m         response \u001b[38;5;241m=\u001b[39m connection\u001b[38;5;241m.\u001b[39msend_command(command)\n",
      "File \u001b[0;32m~/spark-3.5.1/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:284\u001b[0m, in \u001b[0;36mJavaClient._get_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    281\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n\u001b[1;32m    283\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m connection\u001b[38;5;241m.\u001b[39msocket \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 284\u001b[0m     connection \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_create_new_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/spark-3.5.1/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:291\u001b[0m, in \u001b[0;36mJavaClient._create_new_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_create_new_connection\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    288\u001b[0m     connection \u001b[38;5;241m=\u001b[39m ClientServerConnection(\n\u001b[1;32m    289\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpython_parameters,\n\u001b[1;32m    290\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_property, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 291\u001b[0m     \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_to_java_server\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_thread_connection(connection)\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m connection\n",
      "File \u001b[0;32m~/spark-3.5.1/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:443\u001b[0m, in \u001b[0;36mClientServerConnection.connect_to_java_server\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_connected \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    441\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minitiated_from_client \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 443\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_authenticate_connection\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m Py4JAuthenticationError:\n\u001b[1;32m    445\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclose(reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[0;32m~/spark-3.5.1/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:459\u001b[0m, in \u001b[0;36mClientServerConnection._authenticate_connection\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters\u001b[38;5;241m.\u001b[39mauth_token:\n\u001b[1;32m    455\u001b[0m     cmd \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{1}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    456\u001b[0m         proto\u001b[38;5;241m.\u001b[39mAUTH_COMMAND_NAME,\n\u001b[1;32m    457\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjava_parameters\u001b[38;5;241m.\u001b[39mauth_token\n\u001b[1;32m    458\u001b[0m     )\n\u001b[0;32m--> 459\u001b[0m     answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend_command\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    460\u001b[0m     error, _ \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mis_error(answer)\n\u001b[1;32m    461\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m error:\n",
      "File \u001b[0;32m~/spark-3.5.1/python/lib/py4j-0.10.9.7-src.zip/py4j/clientserver.py:511\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    510\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m--> 511\u001b[0m         answer \u001b[38;5;241m=\u001b[39m smart_decode(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreadline\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    512\u001b[0m         logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAnswer received: \u001b[39m\u001b[38;5;132;01m{0}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(answer))\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;66;03m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    514\u001b[0m         \u001b[38;5;66;03m# answer before the socket raises an error.\u001b[39;00m\n",
      "File \u001b[0;32m/usr/lib64/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sock\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_timeout_occurred \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# eventTime.withWatermark(\"event_time\", \"5 seconds\")\\\n",
    "# .dropDuplicates([\"User\", \"event_time\"])\\\n",
    "# .groupBy(\"User\")\\\n",
    "# .count().writeStream.queryName(\"pyevent_per_window4\").format(\"memory\").outputMode(\"complete\").start()\n",
    "\n",
    "eventTime.withWatermark(\"event_time\", \"5 seconds\")\\\n",
    ".dropDuplicates([\"User\", \"event_time\"])\\\n",
    ".groupBy(\"User\")\\\n",
    ".count().writeStream.queryName(\"pyevent_per_window4\").format(\"memory\").outputMode(\"complete\").stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03cfc69-d9d4-4c08-80e5-0f2a1036758e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
